---
layout: ../../../layouts/DocsLayout.astro
title: Query Result Caching
description: Learn how to enable caching, handle invalidation, and plug in custom cache providers with hypequery
---

# Query Result Caching (Experimental)

hypequery ships with an opt-in caching layer that sits directly on top of `execute()`. It computes deterministic keys from the generated SQL + parameters, deduplicates in-flight requests, and can serve stale results while new data is refreshed in the background. The feature is disabled by default and can be enabled on a per-connection or per-query basis.

> **Note**: Streaming queries are never cached, and pagination helpers force `mode: 'no-store'` until pagination-specific caching semantics are designed.

## Enabling Caching

### Global configuration

Pass `cache` when creating the query builder. Provide a mode, TTL, and optionally a provider (defaults to the built-in in-memory LRU when you supply cache options).

```typescript
import { createQueryBuilder, MemoryCacheProvider } from '@hypequery/clickhouse';

const db = createQueryBuilder({
  host: process.env.CLICKHOUSE_HOST!,
  username: 'default',
  password: process.env.CLICKHOUSE_PASSWORD!,
  database: 'analytics',
  cache: {
    mode: 'stale-while-revalidate',
    ttlMs: 2_000,
    staleTtlMs: 30_000,
    staleIfError: true,
    provider: new MemoryCacheProvider({ maxEntries: 1_000 })
  }
});
```

### Builder-level overrides

Use `.cache()` anywhere in the fluent chain to adjust behavior for the current query:

```typescript
const activeUsers = db
  .table('users')
  .select(['id', 'email'])
  .where('status', 'eq', 'active')
  .cache({ tags: ['users'], ttlMs: 5_000 });
```

### One-off overrides

Pass cache options to `execute()` for one-time behavior changes (without mutating the builder):

```typescript
await activeUsers.execute({ cache: { mode: 'network-first', staleIfError: true } });
```

Need to bypass caching temporarily? Pass `cache: false` (or `.cache(false)` during builder configuration) to force `mode: 'no-store'` without rewriting the rest of the options:

```typescript
const uncached = await activeUsers.execute({ cache: false });
```

Configuration merges in this order: global defaults → `.cache()` → `execute({ cache })`.

## Cache Modes & Semantics

| Mode | Behavior |
|------|----------|
| `cache-first` | Return a fresh cache entry when available; otherwise hit ClickHouse, store, and return. |
| `network-first` | Always hit ClickHouse; fall back to stale data when `staleIfError` is true. |
| `stale-while-revalidate` | Serve fresh entries. If only stale entries exist (within `ttl + staleTtl`), return them immediately and revalidate in the background. |
| `no-store` | Skip cache entirely. Useful for highly dynamic or sensitive queries. |

Additional knobs:

- `ttlMs` / `staleTtlMs`: define freshness + acceptable staleness windows.
- `cacheTimeMs`: GC window for inactive entries (defaults to `ttlMs + staleTtlMs`).
- `dedupe`: disable in-flight deduplication by passing `false`.
- `serialize` / `deserialize`: override JSON serialization with msgpack, superjson, compression, etc.
- `tags`: custom labels for invalidation (automatically merged with derived table names).

Every execution emits cache metadata via the existing logger (`cacheStatus`, `cacheKey`, `cacheMode`, `cacheAgeMs`). Hook into `logger.configure({ onQueryLog })` to forward events to your monitoring stack.

## Stale-While-Revalidate & In-Flight Deduplication

When `mode` is `stale-while-revalidate`, hypequery returns stale-but-acceptable data immediately and triggers a background refresh. To avoid hammering ClickHouse, the library keeps a `Map<cacheKey, Promise>` so concurrent requests reuse the same in-flight execution:

```typescript
const dashboard = await Promise.all([
  db.table('users')
    .select(['status'])
    .count('*', 'total_users')
    .cache({ mode: 'stale-while-revalidate', tags: ['users'] })
    .execute(),
  db.table('orders')
    .sum('total', 'revenue')
    .cache({ mode: 'stale-while-revalidate', tags: ['orders'] })
    .execute()
]);
```

If multiple widgets issue the same query concurrently, only one actual ClickHouse request runs.

## Invalidation & Tagging

`createQueryBuilder` exposes a cache controller for manual invalidation and cache maintenance:

```typescript
await db.cache.invalidateKey('hq:v1:analytics|default:abcd1234');
await db.cache.invalidateTags(['users', 'orders']);
await db.cache.clear(); // clears the current namespace when supported by the provider

// Warm key dashboard queries at start-up
await db.cache.warm([
  () => db.table('users').count().cache({ tags: ['users'] }).execute(),
  () => db.table('orders').sum('total').cache({ tags: ['orders'] }).execute()
]);

// Inspect stats (hitRate counts stale hits as successful serves)
const { hits, misses, staleHits, hitRate } = db.cache.getStats();
```

Tags come from two places:

1. **Derived tags** — the base table and any joined tables.
2. **Manual tags** — provided via `.cache({ tags: [...] })` or `execute({ cache })`.

Providers can optionally implement `deleteByTag(namespace, tag)` and `clearNamespace(namespace)` to support efficient invalidation on external stores. The built-in Memory LRU provider maintains its own tag index in-process.

Cache keys follow the pattern `hq:<version>:<namespace>:<table-or-alias>:<digest>`, which keeps the hashed fingerprint while adding a human-readable prefix to simplify debugging.

## Observability & Stats

Every query builder exposes lightweight cache stats so you can chart hit ratios or alert when misses spike:

```typescript
const stats = db.cache.getStats();
// => { hits, misses, staleHits, revalidations, hitRate }
console.log(`Cache hit rate: ${(stats.hitRate * 100).toFixed(1)}%`);
```

`hitRate` treats `hit` and `stale-hit` events as successful cache serves, giving a clearer view for SWR-heavy dashboards. Pair this with `logger.configure({ onQueryLog })` to forward query-level cache metadata to your observability stack.

## Bring Your Own Cache Provider

Implement the `CacheProvider` interface to connect Redis, Upstash, Cloudflare KV, or any other store:

```typescript
import type { CacheProvider, CacheEntry } from '@hypequery/clickhouse';
import { Redis } from 'ioredis';

class RedisCacheProvider implements CacheProvider<string> {
  constructor(private readonly client = new Redis(process.env.REDIS_URL!)) {}

  async get(key: string) {
    const raw = await this.client.get(key);
    return raw ? JSON.parse(raw) as CacheEntry : null;
  }

  async set(key: string, entry: CacheEntry) {
    await this.client.set(key, JSON.stringify(entry), 'PX', entry.cacheTimeMs || entry.ttlMs);
    if (entry.tags?.length) {
      await Promise.all(entry.tags.map(tag => this.client.sadd(`tag:${tag}`, key)));
    }
  }

  async delete(key: string) {
    await this.client.del(key);
  }

  async deleteByTag(_namespace: string, tag: string) {
    const keys = await this.client.smembers(`tag:${tag}`);
    if (keys.length) {
      await this.client.del(...keys);
    }
    await this.client.del(`tag:${tag}`);
  }
}
```

Use it when creating the query builder:

```typescript
const db = createQueryBuilder({
  host: process.env.CLICKHOUSE_HOST!,
  cache: {
    mode: 'network-first',
    ttlMs: 2_000,
    staleTtlMs: 30_000,
    staleIfError: true,
    provider: new RedisCacheProvider()
  }
});
```

For Upstash (REST) or Cloudflare KV, implement the same `get/set/delete` contract using their HTTP APIs.

## Custom Serialization & Compression

Some workloads benefit from smaller payloads or richer type support. Swap serialization with `serialize` / `deserialize`:

```typescript
import superjson from 'superjson';
import { gzipSync, gunzipSync } from 'zlib';

const db = createQueryBuilder({
  host: 'http://localhost:8123',
  cache: {
    mode: 'cache-first',
    ttlMs: 5_000,
    serialize: (value) => {
      const payload = gzipSync(Buffer.from(superjson.stringify(value)));
      return { payload, byteSize: payload.byteLength };
    },
    deserialize: (raw) => {
      const buffer = typeof raw === 'string' ? Buffer.from(raw, 'base64') : Buffer.from(raw);
      return superjson.parse(gunzipSync(buffer).toString());
    },
    provider: new MemoryCacheProvider({ maxEntries: 500 })
  }
});
```

You can also use `serialize`/`deserialize` at the per-query level for niche cases.

## Best Practices

- **Start conservative**: enable caching per dashboard / workload rather than globally.
- **Use tags**: tag by table, tenant, or dashboard ID so you can invalidate surgically.
- **Observe**: hook `logger.onQueryLog` to track hit/miss rates and adjust TTLs.
- **Avoid volatile SQL**: queries that reference `now()` or highly dynamic filters should stay `no-store`.
- **Handle streaming separately**: streaming APIs intentionally bypass caching.
- **Dispose in-memory providers**: if you rely on `MemoryCacheProvider` in long-running servers, call `provider.dispose()` during shutdown to stop the cleanup interval.

For a hands-on example, see the `cache.test.ts` integration test in the repository—it mirrors a real dashboard flow and shows how cache hits and tag invalidation behave end-to-end.
