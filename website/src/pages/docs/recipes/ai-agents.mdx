---
layout: ../../../layouts/DocsLayout.astro
title: AI agents & automation
description: Safely expose hypequery metrics to LLM-based agents via MCP/LangChain tools.
---

# AI agents & automation

hypequery already knows every metric’s input and output schema. Expose that catalog to AI agents so they can discover, validate, and execute analytics without direct database access.

## Use case

- Enumerate approved metrics for an agent (“What metrics do I have?”)
- Provide JSON schemas so the agent crafts valid inputs
- Execute metrics via `api.run` and return structured results
- Keep prompts honest by showing friendly names/descriptions

## Prerequisites

- A hypequery API (see [HTTP + OpenAPI](/docs/ship/http-openapi))
- Node.js 18+
- Packages: `langchain`, `zod`

## 1. Define metrics with names + schemas

`src/analytics/queries.ts`

```typescript
import { initServe } from '@hypequery/serve';
import { z } from 'zod';
import { db } from './client';

const { define, queries, query } = initServe({
  context: () => ({ db }),
});

export const api = define({
  queries: queries({
    weeklyRevenue: query
      .name('Weekly revenue')
      .describe('Sum of completed orders per ISO week')
      .input(z.object({
        startDate: z.string().datetime(),
        endDate: z.string().datetime(),
      }))
      .output(z.array(z.object({ week: z.string(), revenue: z.number() })))
      .query(async ({ ctx, input }) =>
        ctx.db
          .table('orders')
          .where('created_at', 'gte', input.startDate)
          .where('created_at', 'lte', input.endDate)
          .groupBy(['toISOWeek(created_at) AS week'])
          .sum('amount', 'revenue')
          .orderBy('week', 'ASC')
          .execute()
      ),

    activeUsers: query
      .name('Active users (7-day)')
      .output(z.object({ count: z.number() }))
      .query(async ({ ctx }) => {
        const rows = await ctx.db
          .table('events')
          .where('created_at', 'gte', 'now() - INTERVAL 7 DAY')
          .count('DISTINCT user_id', 'count')
          .execute();
        return rows[0];
      }),
  }),
});
```

## 2. Describe the catalog once

```typescript
const catalog = api.describe();
// catalog.queries → [{ key, name, summary, inputSchema, outputSchema, ... }]
```

Share `catalog` with agents so they know which tools/metrics exist.

## 3. Create a LangChain tool (DynamicStructuredTool)

```typescript
import { DynamicStructuredTool } from 'langchain/tools';
import { z } from 'zod';
import { api } from '@/analytics/queries';

const catalog = api.describe();

export function createAnalyticsTool() {
  return new DynamicStructuredTool({
    name: 'analytics_metric',
    description: 'Call approved analytics metrics by name',
    schema: z.object({
      metric: z.enum(catalog.queries.map((q) => q.key) as [string, ...string[]]),
      params: z.record(z.any()).default({}),
    }),
    func: async ({ metric, params }) => {
      const definition = catalog.queries.find((q) => q.key === metric);
      if (!definition) throw new Error(`Unknown metric: ${metric}`);

      // Optional: log friendly name + schema for transparency
      console.log('Running metric', definition.name ?? metric);

      return api.run(metric as Parameters<typeof api.run>[0], {
        input: params,
      });
    },
  });
}
```

## 4. Wire the tool into your agent

```typescript
import { initializeAgentExecutorWithOptions } from 'langchain/agents';
import { ChatOpenAI } from '@langchain/openai';
import { createAnalyticsTool } from './analytics-tool';

const analyticsTool = createAnalyticsTool();

const agent = await initializeAgentExecutorWithOptions(
  [analyticsTool],
  new ChatOpenAI({ modelName: 'gpt-4o' }),
  { agentType: 'structured-chat-zero-shot-react-description' }
);

const response = await agent.invoke({
  input: 'Show me weekly revenue for January 2024 and flag any drop >10%',
});
```

## 5. Optional: Slack command example

```typescript
app.command('/analytics', async ({ command, ack, respond }) => {
  await ack();

  const catalog = api.describe();
  const metric = await llm.chooseMetric(command.text, catalog.queries.map((q) => q.key));
  const definition = catalog.queries.find((q) => q.key === metric);
  const params = await llm.extractParams(command.text, definition?.inputSchema);

  const data = await api.run(metric as Parameters<typeof api.run>[0], { input: params });

  await respond(formatData(data, { name: definition?.name ?? metric }));
});
```

## Tips

- **Names & summaries**: Set `query.name()` / `.describe()` so agents can surface human-readable labels.
- **Schema validation**: Agents see the JSON Schema representation of your Zod inputs/outputs via `api.describe()`.
- **Rate limiting**: Use query-level middleware to throttle agent traffic if needed.
- **Custom metadata**: `query.custom({ cost: 'high' })` lets you annotate metrics with extra hints for agents.

## Next steps

- Combine with [Multi-tenancy isolation](/docs/ship/multi-tenancy) so each agent only sees its tenant’s data
- Emit catalog JSON over MCP if you are integrating with OpenAI’s foundational tools
- Log agent usage via `hooks.onRequestStart` / `onRequestEnd` for auditing
